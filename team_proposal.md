## Leading Question 
* Our general goal is to solve the question “what is the safest route between any two places in Champaign County.” We can further predict the probability of having a car accident when driving a certain route, as well as find the safest road connections (e.g. intersections with smallest probability of a car accident).

## Dataset Acquisition
* **Data Format**: We will use three datasets as our inputs: a set of nodes and edges containing the road network of Champaign County, historical records of car accident locations, and the average daily drivers on each road. The first dataset will be read as a shapefile and will be pulled from [https://www.sciencebase.gov/catalog/item/5a5f36c1e4b06e28e9bfc1c0] (https://www.sciencebase.gov/catalog/item/5a5f36c1e4b06e28e9bfc1c0). It contains around 1,000,000 records on road sections in Illinois, but we will trim this data to just Champaign County (convenient as the county is mostly a square). The dataset additionally stores positions and lengths of road sections. The second dataset is stored in JSON and will be pulled from [https://data.ccrpc.org/dataset/traffic-crashes](https://data.ccrpc.org/dataset/traffic-crashes): There are a total of 1865 records of interest. Each record stores positional data to severe traffic accidents. The third dataset is also stored in JSON and will be pulled from [https://data.ccrpc.org/dataset/traffic_counts](https://data.ccrpc.org/dataset/traffic_counts): This dataset stores 7139 records marking the beginning and ending positions of a road segment and the average daily drivers on these segments.
* **Data Correction**: We must presume that both the average traffic data and the crashes data are valid. What we can check is parity issues between the datasets related to positions of accidents and road segments. If the data for a daily traffic position or a crash position does not match a road network position, we will see if the nearest road network position is within an accepted tolerance. If it is, then we just assign the crash position or daily driver count to the position’s associated road. If it is not, we will note the record for manual review. If an average traffic record is missing, we will use the average traffic counts of all roads connected to the road of interest. If a connected group of roads is included in the second or third dataset, but not in the first dataset, we will make sure these roads are included. We assume that the crash records are mostly to totally complete and a lack of crash records for a road segment means that no crashes occurred on that segment. Additionally, we will look for outliers in average traffic data and remove values for potential errors.
* **Data Storage**: We are using an adjacency list graph implementation, that is, a node vector and an edge list, with the nodes storing positions, and the edges storing both length and accident probabilities of roads between nodes. An additional data structure we will use is a k-d tree. This will be used to find the closest node in the network to any given point. So, our implementation will have space complexity $O(n+m)$, where $n$ is the number of nodes, or connections between road sections, and $m$ is the number of edges, or road sections.

## Algorithms
* **Function Inputs**: To convert the datasets into a graph, we will start by reading the road network (first) dataset and constructing a graph of the roads of Champaign County. We will then read the crash records (second dataset) and store the number of crashes on each road segment into the edge set. We will finally read the daily driver records (third dataset) and find a probability estimate for having an accident on each road section. The only other inputs we expect are arbitrary positions given by the user. To address this, we will use a k-d tree to find the closest node in our graph from the user's input position. We plan on implementing either Dijkstra’s algorithm or the A* search algorithm to find the shortest path between two nodes. One heurestic we can use for A* is the direct distance between two intersections (nodes) multiplied by the smallest probability of crashing over length in the graph. With this heuristic, we can find the shortest "distance" (in terms of safety) between two nodes. Note that due to the nature of probabilities, we need to modify our shortest path algorithms to be multiplicative instead of additive. As such, the shortest path algorithms will find the safest route to travel on (i.e. the path that connects nodes A and B which has the minimum probability of a severe crash.) Another algorithm we can implement is betweenness centrality, which would find the safest intersection (node) in the road network. Both BFS and DFS are equivalently easy to implement.

* **Function Outputs**: Our "shortest path" algorithm would output the safest path (sequence of nodes/edges) and the probability of getting into a severe accident on that path. This data could be written to a file or directly to the terminal. For betweenness centrality, our algorithm would output a list of intersections (nodes) ordered by safety (centrality). This will then be outputted as a file. For our data visualization, we will rely on external libraries and feed these libraries with the positions of roads and intersections acquired from the output of other functions.

* **Function Efficiency**: We believe constructing the graph would take at least a time complexity of $O(n^2 + anm + nm + m)$ and a space complexity of at least $O(n + m + a)$, where $n$ is the number of nodes, or connection points; $m$ is the number of edges, or road sections; and a is the number of severe car accidents. Dijkstra’s algorithm will have at least $O(n^2)$ space and time complexity, as we probably will not implement it using a Fibonacci heap. The A* algorithm should be $O(n)$ space complexity and $O(m)$ time complexity. Betweenness centrality will have at least $O(m^3)$ time complexity and $O(n^3)$ space complexity. Both DFS and BFS should have a time complexity of $O(n + m)$ and a space complexity of $O(m)$.


## Timeline
* 11/5 to 11/11: Clean data and implement data structure construction methods
* 11/12 to 11/18: Implement a search algorithm and a shortest path algorithm.
* 11/19 to 11/25: Implement betweenness centrality and begin to work on data visualization.
* 11/26 to 12/2: Finish data visualization, polish code, and ensure the completion of all final project deliverables .
* 12/3 to 12/8: Prepare and record presentation.
